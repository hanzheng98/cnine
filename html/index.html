<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" />

    <meta name="generator" content="sphinx-4.2.0, furo 2021.10.09"/>
        <title>cnine documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?digest=0254c309f5cadf746f1a613e7677379ac9c8cdcd" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?digest=16fb25fabf47304eee183a5e9af80b1ba98259b1" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  body[data-theme="dark"] {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
  @media (prefers-color-scheme: dark) {
    body:not([data-theme="light"]) {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" />
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="#"><div class="brand">cnine  documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="#">
  
  
  <span class="sidebar-brand-text">cnine  documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  
</div>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="cnine">
<h1>cnine<a class="headerlink" href="#cnine" title="Permalink to this headline">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<p><cite>cnine</cite> is a lightweight C++ tensor library with a CUDA backend and optional Python interface.
<cite>cnine</cite> is designed to expose GP-GPU functionality to the C++ or Python programmer.</p>
<p><cite>cnine</cite> is written by Risi Kondor at the University of Chicago and is released under the
<a class="reference external" href="https://www.mozilla.org/en-US/MPL/2.0/">Mozilla public license v.2.0</a>.</p>
<p>This document provides documentation for cnine’s Python interface. Not all features in the C++ library
are available through this interface. The documentation of the C++ API can be found in pdf format
in the package’s <code class="docutils literal notranslate"><span class="pre">doc</span></code> directory.</p>
<section id="installation">
<h2>Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h2>
<p>Installing cnine requires the following:</p>
<ol class="arabic simple">
<li><p>C++11 or higher</p></li>
<li><p>Python</p></li>
<li><p>Pybind11</p></li>
<li><p>PyTorch (optional)</p></li>
</ol>
<p>To install cnine follow these steps:</p>
<ol class="arabic simple">
<li><p>Download the cnine package from <a class="reference external" href="https://github.com/risi-kondor/cnine">github</a>.</p></li>
<li><p>Edit the file <code class="docutils literal notranslate"><span class="pre">config.txt</span></code> as necessary.</p></li>
<li><p>Run <code class="docutils literal notranslate"><span class="pre">python</span> <span class="pre">setup.sty</span> <span class="pre">install</span></code> in the <code class="docutils literal notranslate"><span class="pre">python</span></code> directory to compile the package and install it on your
system.</p></li>
</ol>
<p>To use <cite>cnine</cite> from Python, load the corresponding module the usual way with <code class="docutils literal notranslate"><span class="pre">import</span> <span class="pre">cnine</span></code>.
In the following we assume that <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">cnine</span> <span class="pre">import</span> <span class="pre">*</span></code> has also been called,
obviating the need to prefix all <cite>cnine</cite> classes with <code class="docutils literal notranslate"><span class="pre">cnine.</span></code>.</p>
</section>
<section id="known-issues">
<h2>Known issues<a class="headerlink" href="#known-issues" title="Permalink to this headline">¶</a></h2>
<p>GPU functionality is temporarily disabled.</p>
<div class="line-block">
<div class="line"><br/></div>
</div>
</section>
<section id="tensors">
<h2>Tensors<a class="headerlink" href="#tensors" title="Permalink to this headline">¶</a></h2>
<p>The core data types in cnine are real and complex multidimensional arrays.
The corresponding classes are <code class="docutils literal notranslate"><span class="pre">rtensor</span></code> and <code class="docutils literal notranslate"><span class="pre">ctensor</span></code>.
Currently, to facilitate GP-GPU operations, only single precision arithmetic is supported.</p>
<p>We describe basic tensor functionality for the <code class="docutils literal notranslate"><span class="pre">rtensor</span></code> class.
The <code class="docutils literal notranslate"><span class="pre">ctensor</span></code> class’s interface is analogous.</p>
<section id="creating-tensors">
<h3>Creating tensors<a class="headerlink" href="#creating-tensors" title="Permalink to this headline">¶</a></h3>
<p>The following example shows how to create and print out a <img alt="4\times 4" class="math" src="_images/math/e09ffa3ea05a3d4eea933dfc9ff5f288af38bca5.svg"/>
dimensional tensor filled with zeros.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">[ 0 0 0 0 ]</span>
<span class="go">[ 0 0 0 0 ]</span>
<span class="go">[ 0 0 0 0 ]</span>
<span class="go">[ 0 0 0 0 ]</span>
</pre></div>
</div>
<p>Alternative fill patters are <code class="docutils literal notranslate"><span class="pre">ones</span></code> (a tensor filled with 1s), <code class="docutils literal notranslate"><span class="pre">sequential</span></code> (a tensor filled
with the numbers 0,1,2,… in sequence, <code class="docutils literal notranslate"><span class="pre">identity</span></code> (used to construct an identity matrix),
and <code class="docutils literal notranslate"><span class="pre">gaussian</span></code> (a tensor whose elements are drawn i.i.d. from a standard normal distribution).</p>
<p>The number of tensor dimensions and the dimensions themselves can be read out as follows.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">G</span><span class="o">.</span><span class="n">get_ndims</span><span class="p">()</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">get_dims</span><span class="p">())</span>
<span class="go">(3,4,4)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">get_dim</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
<span class="go">4</span>
</pre></div>
</div>
</section>
<section id="tensor-dimensions">
<h3>Tensor dimensions<a class="headerlink" href="#tensor-dimensions" title="Permalink to this headline">¶</a></h3>
<p>The number of tensor dimensions, the size of a specific dimenion and the <code class="docutils literal notranslate"><span class="pre">gdims</span></code> object corresponding
to all the dimensions are accessed as follows.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">get_ndims</span><span class="p">()</span>
<span class="go">2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">get_dim</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="go">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dims</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">get_dims</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="go">4</span>
</pre></div>
</div>
</section>
<section id="accessing-tensor-elements">
<h3>Accessing tensor elements<a class="headerlink" href="#accessing-tensor-elements" title="Permalink to this headline">¶</a></h3>
<p>Tensor indexing in <cite>cnine</cite> always starts with 0 along each dimension.
The following example shows how tensor elements can be set and read.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">cnine</span> <span class="kn">import</span> <span class="o">*</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">sequential</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">[ 0 1 2 3 ]</span>
<span class="go">[ 4 5 6 7 ]</span>
<span class="go">[ 8 9 10 11 ]</span>
<span class="go">[ 12 13 14 15 ]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">])</span>
<span class="go">6.0</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]]</span><span class="o">=</span><span class="mi">99</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">[ 0 1 2 3 ]</span>
<span class="go">[ 4 5 99 7 ]</span>
<span class="go">[ 8 9 10 11 ]</span>
<span class="go">[ 12 13 14 15 ]</span>
</pre></div>
</div>
</section>
<section id="arithmetic-operations">
<h3>Arithmetic operations<a class="headerlink" href="#arithmetic-operations" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">rtensor</span></code> supports the usual arithmetic tensor and matrix operations.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">sequential</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="o">+</span><span class="n">B</span><span class="p">)</span>
<span class="go">[ 1 2 3 4 ]</span>
<span class="go">[ 5 6 7 8 ]</span>
<span class="go">[ 9 10 11 12 ]</span>
<span class="go">[ 13 14 15 16 ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="o">*</span><span class="mi">5</span><span class="p">)</span>
<span class="go">[ 0 5 10 15 ]</span>
<span class="go">[ 20 25 30 35 ]</span>
<span class="go">[ 40 45 50 55 ]</span>
<span class="go">[ 60 65 70 75 ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="o">*</span><span class="n">A</span><span class="p">)</span>
<span class="go">[ 56 62 68 74 ]</span>
<span class="go">[ 152 174 196 218 ]</span>
<span class="go">[ 248 286 324 362 ]</span>
<span class="go">[ 344 398 452 506 ]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">rtensor</span></code> also offers in-place operators.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">sequential</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">+=</span><span class="n">B</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">[ 1 2 3 4 ]</span>
<span class="go">[ 5 6 7 8 ]</span>
<span class="go">[ 9 10 11 12 ]</span>
<span class="go">[ 13 14 15 16 ]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">-=</span><span class="n">B</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">[ 0 1 2 3 ]</span>
<span class="go">[ 4 5 6 7 ]</span>
<span class="go">[ 8 9 10 11 ]</span>
<span class="go">[ 12 13 14 15 ]</span>
</pre></div>
</div>
</section>
<section id="functions-of-tensors">
<h3>Functions of tensors<a class="headerlink" href="#functions-of-tensors" title="Permalink to this headline">¶</a></h3>
<p>The following shows how to compute the inner product
<img alt="\langle A, B\rangle=\sum_{i_1,\ldots,i_k} A_{i_1,\ldots,i_k} B_{i_1,\ldots,i_k}" class="math" src="_images/math/6c16afcb3b5e73ce4ec263a20541224e22d8bb69.svg"/>
between two tensors and the squared Frobenius norm
<img alt="\vert A\vert^2=\sum_{i_1,\ldots,i_k} \vert A_{i_1,\ldots,i_k}\vert^2" class="math" src="_images/math/8081aafb4f16f2e787ddc81dce695819089114ae.svg"/>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">gaussian</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">[ -1.23974 -0.407472 1.61201 0.399771 ]</span>
<span class="go">[ 1.3828 0.0523187 -0.904146 1.87065 ]</span>
<span class="go">[ -1.66043 -0.688081 0.0757219 1.47339 ]</span>
<span class="go">[ 0.097221 -0.89237 -0.228782 1.16493 ]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inp</span><span class="p">(</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
<span class="go">2.107801675796509</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">norm2</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">18.315340042114258</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">ReLU</span></code> function applies the function <img alt="\textrm{ReLU}(x)=\textrm{max}(0,x)" class="math" src="_images/math/957c22c74da86633352306df1416fca32dc891e0.svg"/> to
each element of the tensor.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">ReLU</span><span class="p">(</span><span class="n">A</span><span class="p">))</span>
<span class="go">[ 0 0 1.61201 0.399771 ]</span>
<span class="go">[ 1.3828 0.0523187 0 1.87065 ]</span>
<span class="go">[ 0 0 0.0757219 1.47339 ]</span>
<span class="go">[ 0.097221 0 0 1.16493 ]</span>
</pre></div>
</div>
</section>
<section id="transposes">
<h3>Transposes<a class="headerlink" href="#transposes" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">transp</span></code> method returns the transpose of a matrix.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">sequential</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">transp</span><span class="p">())</span>
<span class="go">[ 0 4 8 12 ]</span>
<span class="go">[ 1 5 9 13 ]</span>
<span class="go">[ 2 6 10 14 ]</span>
<span class="go">[ 3 7 11 15 ]</span>
</pre></div>
</div>
</section>
<section id="slices-and-reshaping">
<h3>Slices and reshaping<a class="headerlink" href="#slices-and-reshaping" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">slice(i,c)</span></code> method returns the slice of the tensor corresponding to setting the i’th index
equal to c. <code class="docutils literal notranslate"><span class="pre">reshape</span></code> reinterprets the tensor as a tensor of a different shape.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">sequential</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">slice</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="go">[ 2 6 10 14 ]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">.</span><span class="n">reshape</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">[ 0 1 2 3 4 5 6 7 ]</span>
<span class="go">[ 8 9 10 11 12 13 14 15 ]</span>
</pre></div>
</div>
</section>
<section id="gpu-functionality">
<h3>GPU functionality<a class="headerlink" href="#gpu-functionality" title="Permalink to this headline">¶</a></h3>
<p>Tensors can moved back and forth between the host (CPU) and the GPU with the <code class="docutils literal notranslate"><span class="pre">to</span></code> method.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">sequential</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Create a copy of A on the first GPU (GPU0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span><span class="o">=</span><span class="n">B</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Move B back to the host</span>
</pre></div>
</div>
<p>Almost all operations that <cite>cnine</cite> offers on the host are also available on the GPU.
In general, if the operands are on the host, the operation will be performed on the host and
the result is placed on the host. Conversely, if the operands are on the GPU,
the operation will be performed on the GPU and the result placed on the same GPU.</p>
</section>
<section id="gdims-and-gindex">
<h3>gdims and gindex<a class="headerlink" href="#gdims-and-gindex" title="Permalink to this headline">¶</a></h3>
<p>In the previous examples tensors dimensions and tensor indices were specified simply as lists.
As an alternative, tensor dimensions and indices can also be specified using the specialized
classes <cite>gdims</cite> and <cite>gindex</cite>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">dims</span><span class="o">=</span><span class="n">gdims</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
<span class="go">(3,3,5)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">dims</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">dims</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="go">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dims</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">=</span><span class="mi">7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">dims</span><span class="p">)</span>
<span class="go">(3,3,7)</span>
<span class="go">&gt;&gt;&gt;</span>
</pre></div>
</div>
</section>
<section id="complex-tensors">
<h3>Complex tensors<a class="headerlink" href="#complex-tensors" title="Permalink to this headline">¶</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">ctensor</span></code> complex valued tensor class supports all the same operations as <code class="docutils literal notranslate"><span class="pre">rtensor</span></code>.
In addition, it also has <code class="docutils literal notranslate"><span class="pre">conj</span></code> and <code class="docutils literal notranslate"><span class="pre">herm</span></code> methods to take the conjugate
and conjugate transpose (Hermitian conjugate) of the tensor.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">ctensor</span><span class="o">.</span><span class="n">gaussian</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">[ (-1.23974,0.584898) (-0.407472,-0.660558) (1.61201,0.534755) (0.399771,-0.607787) ]</span>
<span class="go">[ (1.3828,0.74589) (0.0523187,-1.75177) (-0.904146,-0.965146) (1.87065,-0.474282) ]</span>
<span class="go">[ (-1.66043,-0.546571) (-0.688081,-0.0384917) (0.0757219,0.194947) (1.47339,-0.485144) ]</span>
<span class="go">[ (0.097221,-0.370271) (-0.89237,-1.12408) (-0.228782,1.73664) (1.16493,0.882195) ]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">conj</span><span class="p">())</span>
<span class="go">[ (-1.23974,-0.584898) (-0.407472,0.660558) (1.61201,-0.534755) (0.399771,0.607787) ]</span>
<span class="go">[ (1.3828,-0.74589) (0.0523187,1.75177) (-0.904146,0.965146) (1.87065,0.474282) ]</span>
<span class="go">[ (-1.66043,0.546571) (-0.688081,0.0384917) (0.0757219,-0.194947) (1.47339,0.485144) ]</span>
<span class="go">[ (0.097221,0.370271) (-0.89237,1.12408) (-0.228782,-1.73664) (1.16493,-0.882195) ]</span>
</pre></div>
</div>
</section>
<section id="storage-details">
<h3>Storage details<a class="headerlink" href="#storage-details" title="Permalink to this headline">¶</a></h3>
<p><cite>cnine</cite> is designed to be able to switch between different C++ backend classes for its core data types.
The default backend class for real tensors is <code class="docutils literal notranslate"><span class="pre">RtensorA</span></code> and for complex tensors is <code class="docutils literal notranslate"><span class="pre">CtensorA</span></code>.
<code class="docutils literal notranslate"><span class="pre">RtensorA</span></code> stores a tensor of dimensions <img alt="d_1\times\ldots\times d_k" class="math" src="_images/math/32cd00a5e0ce6e93f9d616d3991f6c71e697b7dc.svg"/> as a single contiguous array of
<img alt="d_1 \ldots d_k" class="math" src="_images/math/cd6032da681718c182320df23c095d9551543db2.svg"/> floating point numbers in row major order.
<code class="docutils literal notranslate"><span class="pre">CtensorA</span></code> stores a complex tensor as a single array consisting of the
real part of the tensor followed by the imaginary part.
To facilitate memory access on the GPU, the offset of the imaginary part is rounded up to the nearest
multiple of 128 bytes.</p>
<p>A tensor object’s header, including information about tensor dimensions, strides, etc., is always resident on
the host. When a tensor array is moved to the GPU, only the array containing the tensor entries
is moved to the  GPU’s global memory.</p>
</section>
</section>
<section id="tensor-arrays">
<h2>Tensor arrays<a class="headerlink" href="#tensor-arrays" title="Permalink to this headline">¶</a></h2>
<p>The basic device for parallelizing computations on the GPU in <cite>cnine</cite> are tensor arrays.
A tensor array is an array of tensors of the same size arranged in a contiguous data structure:
<code class="docutils literal notranslate"><span class="pre">rtensor_arr</span></code> corresponds to an array of real tensors, whereas <code class="docutils literal notranslate"><span class="pre">ctensor_arr</span></code> corresponds
to an array of complex tensors.
We describe the basic functionality of tensor arrays for the <code class="docutils literal notranslate"><span class="pre">rtensor_arr</span></code> class.
The API of <code class="docutils literal notranslate"><span class="pre">ctensor_arr</span></code> is analogous.</p>
<section id="creating-tensor-arrays">
<h3>Creating tensor arrays<a class="headerlink" href="#creating-tensor-arrays" title="Permalink to this headline">¶</a></h3>
<p>The following example shows how to create a <img alt="2\times 2" class="math" src="_images/math/722e9acdc2f80ea3b4a4befe6fb5ef31a07f24ef.svg"/> array of <img alt="4\times 4" class="math" src="_images/math/e09ffa3ea05a3d4eea933dfc9ff5f288af38bca5.svg"/>
dimensional tensors filled with random numbers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">gaussian</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">Cell (0,0)</span>
<span class="go">[ -1.23974 -0.407472 1.61201 0.399771 ]</span>
<span class="go">[ 1.3828 0.0523187 -0.904146 1.87065 ]</span>
<span class="go">[ -1.66043 -0.688081 0.0757219 1.47339 ]</span>
<span class="go">[ 0.097221 -0.89237 -0.228782 1.16493 ]</span>


<span class="go">Cell (0,1)</span>
<span class="go">[ -1.50279 0.570759 -0.929941 -0.934988 ]</span>
<span class="go">[ -0.764676 0.250854 -0.188164 -1.51315 ]</span>
<span class="go">[ 1.32256 1.93468 1.25244 1.0417 ]</span>
<span class="go">[ -0.696964 0.537104 0.694816 0.541231 ]</span>


<span class="go">Cell (1,0)</span>
<span class="go">[ -1.13769 -1.22027 0.111152 -0.672931 ]</span>
<span class="go">[ -1.39814 -0.477463 0.643125 1.37519 ]</span>
<span class="go">[ -1.2589 0.259477 -1.6247 -0.996947 ]</span>
<span class="go">[ -0.149277 -1.3338 -1.44352 0.65806 ]</span>


<span class="go">Cell (1,1)</span>
<span class="go">[ -1.20183 -0.399454 -0.727057 0.43853 ]</span>
<span class="go">[ -0.42954 -2.20967 -1.22569 0.73464 ]</span>
<span class="go">[ 0.630166 0.137796 0.674001 -0.281158 ]</span>
<span class="go">[ -1.1945 1.06918 -1.2115 -2.1947 ]</span>
</pre></div>
</div>
</section>
<section id="tensor-array-dimensions">
<h3>Tensor array dimensions<a class="headerlink" href="#tensor-array-dimensions" title="Permalink to this headline">¶</a></h3>
<p>The array dimensions and cell dimensions of a tensor array are accessed as follows.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">gaussian</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">adims</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">get_adims</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">adims</span><span class="p">)</span>
<span class="go">(2,2)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cdims</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">get_cdims</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">cdims</span><span class="p">)</span>
<span class="go">(4,4)</span>
</pre></div>
</div>
</section>
<section id="accessing-tensor-cells">
<h3>Accessing tensor cells<a class="headerlink" href="#accessing-tensor-cells" title="Permalink to this headline">¶</a></h3>
<p>Individual tensors in the tensor array, called <cite>cells</cite>, can be accessed similarly to how tensor
elements are accessed in regular tensors.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">A</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="go">[ -1.50279 0.570759 -0.929941 -0.934988 ]</span>
<span class="go">[ -0.764676 0.250854 -0.188164 -1.51315 ]</span>
<span class="go">[ 1.32256 1.93468 1.25244 1.0417 ]</span>
<span class="go">[ -0.696964 0.537104 0.694816 0.541231 ]</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]]</span><span class="o">=</span><span class="n">A</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="go">Cell (0,0)</span>
<span class="go">[ -1.23974 -0.407472 1.61201 0.399771 ]</span>
<span class="go">[ 1.3828 0.0523187 -0.904146 1.87065 ]</span>
<span class="go">[ -1.66043 -0.688081 0.0757219 1.47339 ]</span>
<span class="go">[ 0.097221 -0.89237 -0.228782 1.16493 ]</span>


<span class="go">Cell (0,1)</span>
<span class="go">[ -1.23974 -0.407472 1.61201 0.399771 ]</span>
<span class="go">[ 1.3828 0.0523187 -0.904146 1.87065 ]</span>
<span class="go">[ -1.66043 -0.688081 0.0757219 1.47339 ]</span>
<span class="go">[ 0.097221 -0.89237 -0.228782 1.16493 ]</span>


<span class="go">Cell (1,0)</span>
<span class="go">[ -1.13769 -1.22027 0.111152 -0.672931 ]</span>
<span class="go">[ -1.39814 -0.477463 0.643125 1.37519 ]</span>
<span class="go">[ -1.2589 0.259477 -1.6247 -0.996947 ]</span>
<span class="go">[ -0.149277 -1.3338 -1.44352 0.65806 ]</span>


<span class="go">Cell (1,1)</span>
<span class="go">[ -1.20183 -0.399454 -0.727057 0.43853 ]</span>
<span class="go">[ -0.42954 -2.20967 -1.22569 0.73464 ]</span>
<span class="go">[ 0.630166 0.137796 0.674001 -0.281158 ]</span>
<span class="go">[ -1.1945 1.06918 -1.2115 -2.1947 ]</span>
</pre></div>
</div>
</section>
<section id="cellwise-operations">
<h3>Cellwise operations<a class="headerlink" href="#cellwise-operations" title="Permalink to this headline">¶</a></h3>
<p>Tensor arrays support the same arithmetic operations as regular tensors.
By default, a given operation is applied to each cell of the array independently.
For example, the result of adding an <img alt="n\times m" class="math" src="_images/math/819aa26e0dcbbeb8fe9b89e07303d4420d158ccf.svg"/> tensor array <code class="docutils literal notranslate"><span class="pre">A</span></code> to another <img alt="n\times m" class="math" src="_images/math/819aa26e0dcbbeb8fe9b89e07303d4420d158ccf.svg"/>
tensor array <code class="docutils literal notranslate"><span class="pre">A</span></code> is an <img alt="n\times m" class="math" src="_images/math/819aa26e0dcbbeb8fe9b89e07303d4420d158ccf.svg"/> array in which the <img alt="(i,j)" class="math" src="_images/math/9a109dd7181dc89387b1cddb5f9cd7468859b440.svg"/> cell is the sum
of the corresponding cells in <code class="docutils literal notranslate"><span class="pre">A</span></code> and <code class="docutils literal notranslate"><span class="pre">B</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span><span class="o">=</span><span class="n">A</span><span class="o">+</span><span class="n">B</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">C</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
</pre></div>
</div>
</section>
<section id="broadcast-operations">
<h3>Broadcast operations<a class="headerlink" href="#broadcast-operations" title="Permalink to this headline">¶</a></h3>
<p>Applying a binary operation to a tensor array and a regular tensor corresponds to
first broadcasting the tensor to an array of the same size and then applying the operation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">rtensor</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span><span class="o">=</span><span class="n">A</span><span class="o">+</span><span class="n">B</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
<span class="go">Cell (0,0)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>


<span class="go">Cell (0,1)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>


<span class="go">Cell (1,0)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>


<span class="go">Cell (1,1)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
</pre></div>
</div>
</section>
<section id="widening-and-reduction">
<h3>Widening and reduction<a class="headerlink" href="#widening-and-reduction" title="Permalink to this headline">¶</a></h3>
<p>Summing the array along a given array dimension is called <cite>reduction</cite>, whereas copying it multiple times to
create a new array dimension is called <cite>widening</cite>.
On the GPU, both these operations are performed in <cite>cnine</cite> with fast, parallelized algorithms.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">gaussian</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="go">Cell (0)</span>
<span class="go">[ -0.610066 -1.75872 0.0605343 0.221048 ]</span>
<span class="go">[ -0.485987 0.911379 -0.117453 -2.9732 ]</span>
<span class="go">[ -2.15961 1.34379 0.878445 0.246828 ]</span>
<span class="go">[ -0.993059 -0.996571 0.578766 -1.27511 ]</span>


<span class="go">Cell (1)</span>
<span class="go">[ 1.6495 -1.15005 2.06733 -1.53783 ]</span>
<span class="go">[ -1.38929 0.878757 0.348551 0.871658 ]</span>
<span class="go">[ -2.09839 -0.0545999 -1.23761 0.399476 ]</span>
<span class="go">[ -1.30456 -0.378178 1.31794 0.917212 ]</span>


<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span><span class="o">=</span><span class="n">B</span><span class="o">.</span><span class="n">widen</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
<span class="go">Cell (0,0)</span>
<span class="go">[ -0.610066 -1.75872 0.0605343 0.221048 ]</span>
<span class="go">[ -0.485987 0.911379 -0.117453 -2.9732 ]</span>
<span class="go">[ -2.15961 1.34379 0.878445 0.246828 ]</span>
<span class="go">[ -0.993059 -0.996571 0.578766 -1.27511 ]</span>


<span class="go">Cell (0,1)</span>
<span class="go">[ -0.610066 -1.75872 0.0605343 0.221048 ]</span>
<span class="go">[ -0.485987 0.911379 -0.117453 -2.9732 ]</span>
<span class="go">[ -2.15961 1.34379 0.878445 0.246828 ]</span>
<span class="go">[ -0.993059 -0.996571 0.578766 -1.27511 ]</span>


<span class="go">Cell (0,2)</span>
<span class="go">[ -0.610066 -1.75872 0.0605343 0.221048 ]</span>
<span class="go">[ -0.485987 0.911379 -0.117453 -2.9732 ]</span>
<span class="go">[ -2.15961 1.34379 0.878445 0.246828 ]</span>
<span class="go">[ -0.993059 -0.996571 0.578766 -1.27511 ]</span>


<span class="go">Cell (1,0)</span>
<span class="go">[ 1.6495 -1.15005 2.06733 -1.53783 ]</span>
<span class="go">[ -1.38929 0.878757 0.348551 0.871658 ]</span>
<span class="go">[ -2.09839 -0.0545999 -1.23761 0.399476 ]</span>
<span class="go">[ -1.30456 -0.378178 1.31794 0.917212 ]</span>


<span class="go">Cell (1,1)</span>
<span class="go">[ 1.6495 -1.15005 2.06733 -1.53783 ]</span>
<span class="go">[ -1.38929 0.878757 0.348551 0.871658 ]</span>
<span class="go">[ -2.09839 -0.0545999 -1.23761 0.399476 ]</span>
<span class="go">[ -1.30456 -0.378178 1.31794 0.917212 ]</span>


<span class="go">Cell (1,2)</span>
<span class="go">[ 1.6495 -1.15005 2.06733 -1.53783 ]</span>
<span class="go">[ -1.38929 0.878757 0.348551 0.871658 ]</span>
<span class="go">[ -2.09839 -0.0545999 -1.23761 0.399476 ]</span>
<span class="go">[ -1.30456 -0.378178 1.31794 0.917212 ]</span>
</pre></div>
</div>
</section>
<section id="id1">
<h3>GPU functionality<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Tensor arrays can moved back and forth between the host (CPU) and the GPU similarly to tensors.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">sequential</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># Create a copy of A on the first GPU (GPU0)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span><span class="o">=</span><span class="n">B</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1"># Move B back to the host</span>
</pre></div>
</div>
</section>
<section id="id2">
<h3>Storage details<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>The default C++ backend class for real tensors arrays is <code class="docutils literal notranslate"><span class="pre">RtensorArrayA</span></code>
and for complex tensor arrays is <code class="docutils literal notranslate"><span class="pre">CtensorArrayA</span></code>.
<code class="docutils literal notranslate"><span class="pre">RtensorArrayA</span></code> stores an <img alt="D_1\times \ldots \times D_K" class="math" src="_images/math/acf705b40686b903a367c1a55a843afba22c2dda.svg"/> array of  <img alt="d_1\times\ldots\times d_k" class="math" src="_images/math/32cd00a5e0ce6e93f9d616d3991f6c71e697b7dc.svg"/>
dimensional tensors essentially the same way that <code class="docutils literal notranslate"><span class="pre">RtensorA</span></code> would store a single
<img alt="D_1\times \ldots \times D_K\times d_1\times\ldots\times d_k" class="math" src="_images/math/b17487aa69d14a3b431e07af0bc75bdaa3b39fa7.svg"/> dimensional tensor.
An important caveat however, is that
the stride between consecutive cells is rounded up to the nearest multiple of 128 bytes.
While this facilitates memory access, especially on the GPU, it makes it somewhat harder to
convert a <code class="docutils literal notranslate"><span class="pre">tensor_array</span></code> object to a single tensor in e.g.. <cite>PyTorch</cite>.
<code class="docutils literal notranslate"><span class="pre">CtensorArrayA</span></code> store a complex tensor array in a single array, essentially as two
one tensor array followed by another.</p>
<p>A tensor array object’s header, including information about tensor dimensions, strides, etc., is always resident on
the host. When a tensor array is moved to the GPU, only the array containing the actual tensor entries
is moved to the  GPU’s global memory.</p>
</section>
</section>
<section id="cell-maps-and-cell-operators">
<h2>Cell maps and cell operators<a class="headerlink" href="#cell-maps-and-cell-operators" title="Permalink to this headline">¶</a></h2>
<p><cite>cnine</cite> takes advantage of the parallelism afforded by GPUs via cell maps and cell operators.
A <cite>cell operator</cite> is an operation such as tensor addition, matrix multiplication, etc., that can
be applied to a single cell in a tensor array or a pair of cells in two different tensor
arrays, yielding a single cell as a result. A cell operator typically defines two different
implementations of the same operation: one for the case when the operands are on the host, and one
for the case when they are on the GPU.</p>
<p>A <cite>cell map</cite> is a C++ template class that determines in what pattern a given cell operator is
applied to a combination of tensor arrays. For example, the cell map can be cellwise, capturing
an outer product, inner product or determined by a cell mask object corresponding to a graph of
interactions.</p>
<p>The power of the cell map/operator formalism lies in the fact that any cell operator can be combined
with any cell map. Moreover, when applied on the GPU, <cite>cnine</cite> will perform the individual cell operations
in parallel at the thread block level, meaning that each cell operation will be mapped to a separate
streaming multiprocessor. Thus, according to the general architectural restrictions of NVIDIA GPU’s,
the cell operation itself can utilize up to 1024 GPU threads, which can efficiently share data
with each other via the multiprocessors shared memory.</p>
<p>The use of cell maps and cell operators from Python is limited by the fact that on the C++
side they are implemented via templates. It is not feasible to compile all possible template
instantiations into the Python <code class="docutils literal notranslate"><span class="pre">cnine</span></code> module. Rather for for any new combination of cell operator/
cell map, the Python binding code in <code class="docutils literal notranslate"><span class="pre">cnine_py.cpp</span></code> is expected to be updated manually and
the module has to be compiled anew.</p>
<p>Here we demonstrate the cell map functionality via a single cell operator, <code class="docutils literal notranslate"><span class="pre">RtensorA_add_plus_cop</span></code>.</p>
<section id="cellwise-cmap">
<h3>Cellwise Cmap<a class="headerlink" href="#cellwise-cmap" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cellwise_add_plus</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
<span class="go">Cell (0,0)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>


<span class="go">Cell (0,1)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>


<span class="go">Cell (1,0)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>


<span class="go">Cell (1,1)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
</pre></div>
</div>
</section>
<section id="inner-cmap">
<h3>Inner Cmap<a class="headerlink" href="#inner-cmap" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inner_add_plus</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
<span class="go">Cell (0,0)</span>
<span class="go">[ 2 2 2 ]</span>
<span class="go">[ 2 2 2 ]</span>
<span class="go">[ 2 2 2 ]</span>
</pre></div>
</div>
</section>
<section id="outer-cmap">
<h3>Outer Cmap<a class="headerlink" href="#outer-cmap" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">outer_add_plus</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
<span class="go">Cell (0,0)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>


<span class="go">Cell (0,1)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>


<span class="go">Cell (1,0)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>


<span class="go">Cell (1,1)</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
<span class="go">[ 1 1 1 ]</span>
</pre></div>
</div>
</section>
<section id="mprod-cmap">
<h3>Mprod cmap<a class="headerlink" href="#mprod-cmap" title="Permalink to this headline">¶</a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">A</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">B</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span><span class="o">=</span><span class="n">rtensor_arr</span><span class="o">.</span><span class="n">zero</span><span class="p">([</span><span class="mi">2</span><span class="p">],[</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mprod_add_plus</span><span class="p">(</span><span class="n">C</span><span class="p">,</span><span class="n">A</span><span class="p">,</span><span class="n">B</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">print</span><span class="p">(</span><span class="n">C</span><span class="p">)</span>
<span class="go">Cell (0)</span>
<span class="go">[ 4 4 4 ]</span>
<span class="go">[ 4 4 4 ]</span>
<span class="go">[ 4 4 4 ]</span>


<span class="go">Cell (1)</span>
<span class="go">[ 4 4 4 ]</span>
<span class="go">[ 4 4 4 ]</span>
<span class="go">[ 4 4 4 ]</span>
</pre></div>
</div>
</section>
</section>
</section>
<section id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>

        <div class="related-information">
              Copyright &#169; 2021, Risi Kondor |
            Built with <a href="https://www.sphinx-doc.org/">Sphinx</a>
              and
              <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
              <a href="https://github.com/pradyunsg/furo">Furo theme</a>. |
            <a class="muted-link" href="_sources/index.rst.txt"
               rel="nofollow">
              Show Source
            </a>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">cnine</a><ul>
<li><a class="reference internal" href="#installation">Installation</a></li>
<li><a class="reference internal" href="#known-issues">Known issues</a></li>
<li><a class="reference internal" href="#tensors">Tensors</a><ul>
<li><a class="reference internal" href="#creating-tensors">Creating tensors</a></li>
<li><a class="reference internal" href="#tensor-dimensions">Tensor dimensions</a></li>
<li><a class="reference internal" href="#accessing-tensor-elements">Accessing tensor elements</a></li>
<li><a class="reference internal" href="#arithmetic-operations">Arithmetic operations</a></li>
<li><a class="reference internal" href="#functions-of-tensors">Functions of tensors</a></li>
<li><a class="reference internal" href="#transposes">Transposes</a></li>
<li><a class="reference internal" href="#slices-and-reshaping">Slices and reshaping</a></li>
<li><a class="reference internal" href="#gpu-functionality">GPU functionality</a></li>
<li><a class="reference internal" href="#gdims-and-gindex">gdims and gindex</a></li>
<li><a class="reference internal" href="#complex-tensors">Complex tensors</a></li>
<li><a class="reference internal" href="#storage-details">Storage details</a></li>
</ul>
</li>
<li><a class="reference internal" href="#tensor-arrays">Tensor arrays</a><ul>
<li><a class="reference internal" href="#creating-tensor-arrays">Creating tensor arrays</a></li>
<li><a class="reference internal" href="#tensor-array-dimensions">Tensor array dimensions</a></li>
<li><a class="reference internal" href="#accessing-tensor-cells">Accessing tensor cells</a></li>
<li><a class="reference internal" href="#cellwise-operations">Cellwise operations</a></li>
<li><a class="reference internal" href="#broadcast-operations">Broadcast operations</a></li>
<li><a class="reference internal" href="#widening-and-reduction">Widening and reduction</a></li>
<li><a class="reference internal" href="#id1">GPU functionality</a></li>
<li><a class="reference internal" href="#id2">Storage details</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cell-maps-and-cell-operators">Cell maps and cell operators</a><ul>
<li><a class="reference internal" href="#cellwise-cmap">Cellwise Cmap</a></li>
<li><a class="reference internal" href="#inner-cmap">Inner Cmap</a></li>
<li><a class="reference internal" href="#outer-cmap">Outer Cmap</a></li>
<li><a class="reference internal" href="#mprod-cmap">Mprod cmap</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#indices-and-tables">Indices and tables</a></li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/scripts/main.js"></script>
    </body>
</html>